{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Person_Segmentation_combined.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfD15DP17ea8"
      },
      "source": [
        "import os\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "from skimage import io\r\n",
        "from datetime import datetime\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras.preprocessing.image import load_img\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePHLhzd0SK0D"
      },
      "source": [
        "# Download Data using Kaggle API\r\n",
        "\r\n",
        "https://www.kaggle.com/docs/api\r\n",
        "\r\n",
        "https://www.kaggle.com/general/74235"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4GAwWB2CWfA"
      },
      "source": [
        "## Coco Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OhNp8CqokoH"
      },
      "source": [
        "! pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFb3m87kRJFB"
      },
      "source": [
        "! mkdir ~/.kaggle                 #make directory(folder) named .kaggle\n",
        " \n",
        "! cp kaggle.json ~/.kaggle/       #add file to that folder\n",
        " \n",
        "! chmod 600 ~/.kaggle/kaggle.json        #Change the permissions of the file."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU6GF4DwWbqX"
      },
      "source": [
        "! kaggle datasets download oishee30/cocopersonsegmentation\r\n",
        "\r\n",
        "print(os.listdir('/content'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_hZ4g9FWbwu"
      },
      "source": [
        "! mkdir data        #making directory data\n",
        " \n",
        "! unzip cocopersonsegmentation.zip -d data            #unzipping data into data directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgx5MlZDmSpP"
      },
      "source": [
        "os.remove('/content/cocopersonsegmentation.zip')\r\n",
        "print(os.listdir('/content'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI9AHdt_Y4JR"
      },
      "source": [
        "os.listdir('/content/data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cFIXBNJdzG1"
      },
      "source": [
        "path = '/content/data'\r\n",
        "for folder in os.listdir(path):\r\n",
        "  if '.txt' not in folder:\r\n",
        "    print('No of images in',folder,len(os.listdir(path+'/'+folder)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nKjOo66GmXT"
      },
      "source": [
        "xpath_coco = '/content/data/train2017_new/'\r\n",
        "ypath_coco = '/content/data/train2017_ann/'\r\n",
        "x_test_path = '/content/data/val2017_new/'\r\n",
        "y_test_path = '/content/data/val2017_ann/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsKTmeOMDI63"
      },
      "source": [
        "input_img_paths_coco = sorted([os.path.join(xpath_coco, fname) for fname in os.listdir(xpath_coco)])\r\n",
        "target_img_paths_coco = sorted([os.path.join(ypath_coco, fname) for fname in os.listdir(ypath_coco)])\r\n",
        "\r\n",
        "print(len(input_img_paths_coco), len(target_img_paths_coco))\r\n",
        "for input_path, target_path in zip(input_img_paths_coco[:4], target_img_paths_coco[:4]):\r\n",
        "    print(input_path, \"|\", target_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb4htN3C8mbJ"
      },
      "source": [
        "## Another Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_ozMqlM8ou8"
      },
      "source": [
        "! kaggle datasets download furkankati/person-segmentation-dataset\r\n",
        "\r\n",
        "print(os.listdir('/content'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLB05X5M9fr8"
      },
      "source": [
        "! unzip person-segmentation-dataset.zip -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJiMwOCP9fwy"
      },
      "source": [
        "os.remove('/content/person-segmentation-dataset.zip')\n",
        "print(os.listdir('/content'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9NXpUqEGVaQ"
      },
      "source": [
        "os.listdir('/content/data/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0MN_Fhg9WO5"
      },
      "source": [
        "path = '/content/data/Training/'\n",
        "for folder in os.listdir(path):\n",
        "  if ('.txt' not in folder) and ('.hdf' not in folder) :\n",
        "    print('No of images in',folder,len(os.listdir(path+folder)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6zBIwLUISAy"
      },
      "source": [
        "xpath_89k = '/content/data/Training/input/'\r\n",
        "ypath_89k = '/content/data/Training/Output/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl7-olDn_9OO"
      },
      "source": [
        "xpath_89k = '/content/data/Training/input/'\n",
        "ypath_89k = '/content/data/Training/Output/'\n",
        " \n",
        "input_img_paths_89k = sorted([os.path.join(xpath_89k, fname) for fname in os.listdir(xpath_89k)])\n",
        "target_img_paths_89k = sorted([os.path.join(ypath_89k, fname) for fname in os.listdir(ypath_89k)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K582y4M6IPVe"
      },
      "source": [
        "input_img_paths_89k = sorted([os.path.join(xpath_89k, fname) for fname in os.listdir(xpath_89k)])\r\n",
        "target_img_paths_89k = sorted([os.path.join(ypath_89k, fname) for fname in os.listdir(ypath_89k)])\r\n",
        "\r\n",
        "print(len(input_img_paths_89k), len(target_img_paths_89k))\r\n",
        "for input_path, target_path in zip(input_img_paths_89k[:4], target_img_paths_89k[:4]):\r\n",
        "    print(input_path, \"|\", target_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL4h_J2KmiG1"
      },
      "source": [
        "# Prepare Datset for training\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8owOpmubK89v"
      },
      "source": [
        "train_input_img_paths = input_img_paths_coco.copy()\r\n",
        "target_input_img_paths = target_img_paths_coco.copy()\r\n",
        "\r\n",
        "print(len(train_input_img_paths), len(target_input_img_paths))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhzKhn_NB46-"
      },
      "source": [
        "for img in input_img_paths_89k:\n",
        "  train_input_img_paths.append(img)\n",
        " \n",
        "for img in target_img_paths_89k:\n",
        "  target_input_img_paths.append(img)\n",
        "\n",
        "print(len(train_input_img_paths), len(target_input_img_paths))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbwZvaMexDCP"
      },
      "source": [
        "train_input_img_paths = sorted(train_input_img_paths)    #sorting\n",
        "train_target_img_paths = sorted(target_input_img_paths)   #sorting\n",
        " \n",
        "val_input_img_paths = sorted([os.path.join(x_test_path, fname) for fname in os.listdir(x_test_path)])\n",
        "val_target_img_paths = sorted([os.path.join(y_test_path, fname) for fname in os.listdir(y_test_path)])\n",
        " \n",
        "print(\"Number of training samples:\", len(train_input_img_paths))\n",
        "print(\"Number of validation samples:\", len(val_input_img_paths))\n",
        " \n",
        "for input_path, target_path in zip(train_input_img_paths[:4], train_target_img_paths[:4]):\n",
        "    print(input_path, \"|\", target_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GidnY8HMjA9"
      },
      "source": [
        "n_images = 5\r\n",
        "for i in np.random.randint(0,len(train_input_img_paths),n_images):\r\n",
        " \r\n",
        "  fig = plt.figure(figsize=(12,6))\r\n",
        "  fig.tight_layout()\r\n",
        " \r\n",
        "  plt.subplot(1,2,1)\r\n",
        "  img = plt.imread(train_input_img_paths[i])\r\n",
        "  plt.imshow(img)\r\n",
        "  plt.title('Image')\r\n",
        " \r\n",
        "  plt.subplot(1,2,2)\r\n",
        "  img = plt.imread(train_target_img_paths[i])\r\n",
        "  plt.imshow(img)\r\n",
        "  plt.title('Mask')\r\n",
        " \r\n",
        "  plt.show()\r\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI7S478rNwf5"
      },
      "source": [
        "mask = plt.imread(train_target_img_paths[0])\r\n",
        "print(np.unique(mask, return_counts= True))\r\n",
        "print(mask.shape)\r\n",
        "sns.countplot(mask.ravel())\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZV24HO_N4ZL"
      },
      "source": [
        "mask = plt.imread(train_target_img_paths[-1])\r\n",
        "print(np.unique(mask, return_counts= True))\r\n",
        "print(mask.shape)\r\n",
        "sns.countplot(mask.ravel())\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO7q2JTf2quB"
      },
      "source": [
        "batch_size = 32\n",
        "img_size = (256,256)\n",
        "\n",
        "class Data_Gen(keras.utils.Sequence):\n",
        "    \"\"\"Helper function to iterate over the data (as Numpy arrays).\"\"\"\n",
        " \n",
        "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.input_img_paths = input_img_paths\n",
        "        self.target_img_paths = target_img_paths\n",
        " \n",
        "    def __len__(self):\n",
        "        return len(self.target_img_paths) // self.batch_size                    # 64115//32\n",
        " \n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
        "        i = idx * self.batch_size                                                            # 0\n",
        "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]                # [0: 0+32]\n",
        "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
        " \n",
        "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")           #(32,256,256,3)\n",
        "        for j, path in enumerate(batch_input_img_paths):\n",
        "            img = load_img(path, target_size=self.img_size)\n",
        "            img = np.array(img)/255\n",
        "            x[j] = img\n",
        " \n",
        "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")             #(32,256,256,1)\n",
        "        for j, path in enumerate(batch_target_img_paths):\n",
        "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")        #(256,256)\n",
        "            img = np.array(img)\n",
        "            img[img!=0] = 1\n",
        "            y[j] = np.expand_dims(img, 2)                                                  #(256,256,1)\n",
        " \n",
        "        return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH3NcDI-2qhn"
      },
      "source": [
        "# checking gererator function\r\n",
        "train_gen = Data_Gen(batch_size, img_size, train_input_img_paths, train_target_img_paths)\r\n",
        "val_gen = Data_Gen(batch_size, img_size, val_input_img_paths, val_target_img_paths)\r\n",
        "x, y = train_gen.__getitem__(0)\r\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuYej9OjVSKR"
      },
      "source": [
        "print(y[0].shape)\r\n",
        "print(np.unique(y[0], return_counts= True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YAU_j9TOJJz"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZIb-A942qmN"
      },
      "source": [
        "def downblock(filters, filter_size, previous_layer):\n",
        "  x = layers.Conv2D(filters, filter_size, padding=\"same\")(previous_layer)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        " \n",
        "  x = layers.Conv2D(filters, filter_size, padding=\"same\")(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  \n",
        "  residual = layers.Conv2D(filters, 1, padding=\"same\")(previous_layer)      #separate layer for addintion\n",
        "  x = layers.add([x, residual])  # Add back residual\n",
        " \n",
        "  x = layers.Activation(\"relu\")(x)\n",
        "  p = layers.MaxPooling2D(2)(x)\n",
        " \n",
        "  return x,p\n",
        " \n",
        "def bottleneck(filters, filter_size, previous_layer):\n",
        "  x = layers.Conv2D(filters, filter_size, padding=\"same\")(previous_layer)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        "  x = layers.Dropout(.5)(x)\n",
        "  x = layers.Conv2D(filters, filter_size, padding=\"same\")(x)\n",
        " \n",
        "  residual = layers.Conv2D(filters, 1, padding=\"same\")(previous_layer)      #separate layer for addintion\n",
        "  x = layers.add([x, residual])  # Add back residual\n",
        "  \n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        " \n",
        "  return x\n",
        " \n",
        "def upblock(filters, filter_size, previous_layer, layer_to_concat):\n",
        "  x = layers.Conv2DTranspose(filters, filter_size, strides=2, padding=\"same\")(previous_layer)       #upconvolution\n",
        "  concat = layers.concatenate([x, layer_to_concat])                                                      #concatenation\n",
        " \n",
        "  x = layers.Conv2D(filters, filter_size, padding=\"same\")(concat)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        "  x = layers.Conv2D(filters, filter_size, padding=\"same\")(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        " \n",
        "  residual = layers.Conv2D(filters, 1, padding=\"same\")(concat)      #separate layer for addintion\n",
        "  x = layers.add([x, residual])  # Add back residual\n",
        "  \n",
        "  x = layers.Activation(\"relu\")(x)\n",
        " \n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoPTrlJN5jHU"
      },
      "source": [
        "input_layer = layers.Input(shape = img_size + (3,))\n",
        " \n",
        "conv1, pool1 = downblock(32, 3, input_layer)\n",
        "conv2, pool2 = downblock(64, 3, pool1)\n",
        "conv3, pool3 = downblock(128, 3, pool2)\n",
        " \n",
        "conv4 = bottleneck(256,3,pool3)\n",
        " \n",
        "upconv1 = upblock(128, 3, conv4, conv3)\n",
        "upconv2 = upblock(64, 3, upconv1, conv2)\n",
        "upconv3 = upblock(32, 3, upconv2, conv1)\n",
        " \n",
        "output_layer = layers.Conv2D(1, 1, padding=\"same\", activation='sigmoid')(upconv3)\n",
        "model = keras.Model(input_layer, output_layer)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQimD4fJIFgX"
      },
      "source": [
        "img_file = \"/content/drive/MyDrive/Colab Notebooks/Background_remover/combined.png\"\n",
        "tf.keras.utils.plot_model(model, to_file= img_file, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOoEa6M72qeK"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "opt = Adam(learning_rate=0.001)\n",
        " \n",
        "model.compile(optimizer=opt, loss=\"binary_crossentropy\", \n",
        "              metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=2)])    #metrics=[tf.keras.metrics.MeanIoU(num_classes=2)]\n",
        " \n",
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/Background_remover/modelcombined_{epoch:00d}_{val_loss:03f}.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, save_best_only= False)\n",
        " \n",
        "callbacks = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlffcLVjcEji"
      },
      "source": [
        "start = datetime.now()\n",
        " \n",
        "# Train the model, doing validation at the end of each epoch.\n",
        "epochs = 4\n",
        "model_history = model.fit(train_gen, epochs=epochs, validation_data=val_gen, callbacks=callbacks)\n",
        " \n",
        "end = datetime.now()\n",
        "print(f'Time take to train {epochs} epochs is:', start - end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOuEHk4CRSX1"
      },
      "source": [
        "model_history.history "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2nkI8p6QpLk"
      },
      "source": [
        "train_loss = model_history.history['loss']\r\n",
        "val_loss = model_history.history['val_loss']\r\n",
        "train_acc = model_history.history['accuracy']\r\n",
        "val_acc = model_history.history['val_accuracy']\r\n",
        "train_iou = model_history.history['mean_io_u']\r\n",
        "val_iou = model_history.history['val_mean_io_u']\r\n",
        "\r\n",
        "plt.figure(figsize=(14,6))\r\n",
        "\r\n",
        "plt.subplot(1,3,1)\r\n",
        "plt.plot(train_loss, 'r', label='Training loss')\r\n",
        "plt.plot(val_loss, 'b', label='Validation loss')\r\n",
        "plt.title('Training and Validation Loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss Value')\r\n",
        "plt.yticks(np.arange(0, .5,.05))\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.subplot(1,3,2)\r\n",
        "plt.plot(train_acc, 'r', label='Training acc')\r\n",
        "plt.plot(val_acc, 'b', label='Validation acc')\r\n",
        "plt.title('Training and Validation acc')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('acc')\r\n",
        "plt.yticks(np.arange(0,1.1,.1))\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.subplot(1,3,3)\r\n",
        "plt.plot(train_iou, 'r', label='Training mean_io_u')\r\n",
        "plt.plot(val_iou, 'b', label='Validation mean_io_u')\r\n",
        "plt.title('Training and Validation mean_io_u')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('mean_io_u')\r\n",
        "plt.yticks(np.arange(0,1,.05))\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy8bTrhrwS1C"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrCIWWAPplTU"
      },
      "source": [
        "model = keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/Background_remover/modelcombined_04_0.238711.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odVqKYpXRfAb"
      },
      "source": [
        "def ploting(imgpath, maskpath):\r\n",
        "  plt.figure(figsize=(12,4))\r\n",
        "\r\n",
        "  im = io.imread(imgpath)\r\n",
        "  im = cv2.resize(im,img_size)\r\n",
        "  im = np.array(im)/255\r\n",
        "\r\n",
        "  plt.subplot(1,3,1)\r\n",
        "  plt.title('Original')\r\n",
        "  plt.imshow(im)\r\n",
        "\r\n",
        "  im = im.reshape((1,)+im.shape)\r\n",
        "  im.shape\r\n",
        "\r\n",
        "  pred = model.predict(im)\r\n",
        "  \r\n",
        "  p = pred.copy()\r\n",
        "  p = p.reshape(p.shape[1:-1])\r\n",
        "\r\n",
        "  p[np.where(p>.2)] = 1\r\n",
        "  p[np.where(p<.2)] = 0\r\n",
        "\r\n",
        "  im = io.imread(imgpath)\r\n",
        "  im = cv2.resize(im,img_size)\r\n",
        "  im = np.array(im)\r\n",
        "\r\n",
        "  im[:,:,0] = im[:,:,0]*p \r\n",
        "  im[:,:,0][np.where(p!=1)] = 247\r\n",
        "  im[:,:,1] = im[:,:,1]*p \r\n",
        "  im[:,:,1][np.where(p!=1)] = 231\r\n",
        "  im[:,:,2] = im[:,:,2]*p\r\n",
        "  im[:,:,2][np.where(p!=1)] = 230\r\n",
        "\r\n",
        "  plt.subplot(1,3,2)\r\n",
        "  plt.imshow(im)\r\n",
        "  \r\n",
        "  if maskpath:\r\n",
        "    plt.subplot(1,3,3)\r\n",
        "    mask = io.imread(maskpath)\r\n",
        "    plt.imshow(mask)\r\n",
        "\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQOoM2tR64pK"
      },
      "source": [
        "n_images = 5\r\n",
        "for i in np.random.randint(0,len(val_input_img_paths),n_images):\r\n",
        "  ploting(val_input_img_paths[i], val_target_img_paths[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8VpsDLIQ6GK"
      },
      "source": [
        "# The End"
      ]
    }
  ]
}